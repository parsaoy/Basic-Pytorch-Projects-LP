{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f504c4c9-e61e-484e-a898-c35c7741da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1188a50-33f9-49a5-bf0a-daaa9b1e0c8e",
   "metadata": {},
   "source": [
    "## Building the Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eec1638-935c-49d9-b618-4f8822b35571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Model class that inherits nn.Module\n",
    "# Object Oriented Programming (OOP), not Functional Programming\n",
    "class Model(nn.Module):\n",
    "    # Input Layer (4 Feature of the Iris flower) -->\n",
    "    # Hidden Layer 1 (8 neurons) -->\n",
    "    # Hidden Layer 2 (9 neurons) -->\n",
    "    # Output Layer (3 classes of Iris flower).\n",
    "    def __init__ (self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        super().__init__()  # instantiate our nn.Module\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.out(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9213d2e3-c029-4687-87a0-7c8911e8c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a manual seed for randomization\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b0843-9e7d-4f2b-b735-e91a77d42c94",
   "metadata": {},
   "source": [
    "## Loading Iris Dataset from Gist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62825aa5-8dc3-4992-9b42-3fd88ed64f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset as a data frame\n",
    "url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "my_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19244c23-363c-4fe8-9c5b-24f7349dc387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
       "145           6.7          3.0           5.2          2.3  Virginica\n",
       "146           6.3          2.5           5.0          1.9  Virginica\n",
       "147           6.5          3.0           5.2          2.0  Virginica\n",
       "148           6.2          3.4           5.4          2.3  Virginica\n",
       "149           5.9          3.0           5.1          1.8  Virginica"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15e9cb6-d135-4d5e-9c3b-c870de971510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0             5.1          3.5           1.4          0.2        0\n",
       "1             4.9          3.0           1.4          0.2        0\n",
       "2             4.7          3.2           1.3          0.2        0\n",
       "3             4.6          3.1           1.5          0.2        0\n",
       "4             5.0          3.6           1.4          0.2        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping each variety to a unique integer\n",
    "my_df['variety'] = my_df['variety'].map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\n",
    "\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f74de9-93f4-4966-9ce4-62e35b687380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split -> determine X, y\n",
    "X = my_df.drop('variety', axis=1)\n",
    "y = my_df['variety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ac7019-44be-486d-aa79-cac5fd0bf324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ebb5511-37cc-47bc-a415-181d4763e626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: variety, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1230c721-ec7d-428a-8a44-4a730ef7ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy representations\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6871f58e-c20f-462a-bc8d-ea2bd59f638d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b670c0-e975-4678-bac9-4e76a3a36d57",
   "metadata": {},
   "source": [
    "## Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63fee5ee-d6a8-48cf-bcf4-03667af43a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23bea1d-d525-4897-ae27-c0ddb11a91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7533834-a429-4a04-87cb-767e8023a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X feature to fload tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40901ea8-44f1-4ba1-8bbc-238c5195774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y lables to tensors long\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b3c3f-b292-45df-ac06-5351ca021925",
   "metadata": {},
   "source": [
    "## Define Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03d0753-e7df-4708-bc63-3a0d06e2d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the criterion of model to measure the error.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Choose Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c8261b-d28c-4d9d-9447-95cda14cdfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc19be-36d9-4ece-8eb7-2ba95c9981d5",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffb6466-699e-4a03-9642-863037d2b483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.0846974849700928\n",
      "Epoch: 10 and loss: 0.9178672432899475\n",
      "Epoch: 20 and loss: 0.7620364427566528\n",
      "Epoch: 30 and loss: 0.6275593042373657\n",
      "Epoch: 40 and loss: 0.46693316102027893\n",
      "Epoch: 50 and loss: 0.2876907289028168\n",
      "Epoch: 60 and loss: 0.16747021675109863\n",
      "Epoch: 70 and loss: 0.10634326934814453\n",
      "Epoch: 80 and loss: 0.0805111825466156\n",
      "Epoch: 90 and loss: 0.06965284794569016\n",
      "Epoch: 100 and loss: 0.06449069082736969\n",
      "Epoch: 110 and loss: 0.061621930450201035\n",
      "Epoch: 120 and loss: 0.059805791825056076\n",
      "Epoch: 130 and loss: 0.05852556973695755\n",
      "Epoch: 140 and loss: 0.057549696415662766\n",
      "Epoch: 150 and loss: 0.056762777268886566\n",
      "Epoch: 160 and loss: 0.05610174313187599\n",
      "Epoch: 170 and loss: 0.0555298775434494\n",
      "Epoch: 180 and loss: 0.05502276122570038\n",
      "Epoch: 190 and loss: 0.05456468090415001\n",
      "Epoch: 200 and loss: 0.054144516587257385\n",
      "Epoch: 210 and loss: 0.053754325956106186\n",
      "Epoch: 220 and loss: 0.05338846519589424\n",
      "Epoch: 230 and loss: 0.05304582789540291\n",
      "Epoch: 240 and loss: 0.052877236157655716\n",
      "Epoch: 250 and loss: 0.05272286385297775\n",
      "Epoch: 260 and loss: 0.052200835198163986\n",
      "Epoch: 270 and loss: 0.05191695690155029\n",
      "Epoch: 280 and loss: 0.05167873203754425\n",
      "Epoch: 290 and loss: 0.05142824351787567\n",
      "Epoch: 300 and loss: 0.05119556188583374\n",
      "Epoch: 310 and loss: 0.050972141325473785\n",
      "Epoch: 320 and loss: 0.0507560558617115\n",
      "Epoch: 330 and loss: 0.05054638907313347\n",
      "Epoch: 340 and loss: 0.050343915820121765\n",
      "Epoch: 350 and loss: 0.05014832690358162\n",
      "Epoch: 360 and loss: 0.04996862635016441\n",
      "Epoch: 370 and loss: 0.050793394446372986\n",
      "Epoch: 380 and loss: 0.049835044890642166\n",
      "Epoch: 390 and loss: 0.04947762191295624\n",
      "Epoch: 400 and loss: 0.049368906766176224\n",
      "Epoch: 410 and loss: 0.0492103137075901\n",
      "Epoch: 420 and loss: 0.04906342178583145\n",
      "Epoch: 430 and loss: 0.04892726242542267\n",
      "Epoch: 440 and loss: 0.048801541328430176\n",
      "Epoch: 450 and loss: 0.04868025332689285\n",
      "Epoch: 460 and loss: 0.04856420308351517\n",
      "Epoch: 470 and loss: 0.04845302551984787\n",
      "Epoch: 480 and loss: 0.04836120828986168\n",
      "Epoch: 490 and loss: 0.049820441752672195\n"
     ]
    }
   ],
   "source": [
    "# Train our neural network\n",
    "# Epochs (One run thru all the training data in our network)\n",
    "epochs = 500\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train)  # get predicted results\n",
    "\n",
    "    # Measure the loss / error, gonna be high at first\n",
    "    loss = criterion(y_pred, y_train) # predicted values vs the y_train\n",
    "\n",
    "    # Keep track of our losses, loss is a tensor\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    # print stats every 10 epoch\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "    # Do some back propagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56e23b-a4ca-4edf-9977-217c29bbe5ed",
   "metadata": {},
   "source": [
    "## Plot the Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bd87938-f3cd-47db-939a-9750f9682e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph it out\n",
    "plt.plot(losses, color='red', linestyle='dashed')\n",
    "plt.ylabel('loss/error')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a2d05-cd2a-43dc-b39c-7f3453683896",
   "metadata": {},
   "source": [
    "## Predicting with Trained Model and Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a111bb8b-849a-4980-83a2-69269aaccfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on Test Data Set (validate model on test set)\n",
    "with torch.no_grad():  # basically turn off back propagation\n",
    "    y_pred = model.forward(X_test)\n",
    "    loss = criterion(y_pred, y_test)  # compute Cross-entropy loss/error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eec7a245-5ddc-43ab-9db8-141927673ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0240)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31825d49-023c-403b-98bc-fb0202165aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.) tensor([-1.9143, 10.1336,  2.8532])      \t predicted label:1\t true label:1 \t result:correct \n",
      "2.) tensor([ 12.1616,   3.8262, -11.0541])   \t predicted label:0\t true label:0 \t result:correct \n",
      "3.) tensor([-18.7296,   0.8536,  22.0961])   \t predicted label:2\t true label:2 \t result:correct \n",
      "4.) tensor([-2.9166,  9.0264,  4.0074])      \t predicted label:1\t true label:1 \t result:correct \n",
      "5.) tensor([-3.1749,  9.9211,  4.3195])      \t predicted label:1\t true label:1 \t result:correct \n",
      "6.) tensor([ 11.3071,   3.6489, -10.2455])   \t predicted label:0\t true label:0 \t result:correct \n",
      "7.) tensor([ 1.1811,  9.3988, -0.4448])      \t predicted label:1\t true label:1 \t result:correct \n",
      "8.) tensor([-9.7831,  5.1433, 11.8921])      \t predicted label:2\t true label:2 \t result:correct \n",
      "9.) tensor([-5.1846,  7.4256,  6.5933])      \t predicted label:1\t true label:1 \t result:correct \n",
      "10.) tensor([ 0.4916, 10.0704,  0.2304])      \t predicted label:1\t true label:1 \t result:correct \n",
      "11.) tensor([-7.6388,  6.4512,  9.4239])      \t predicted label:2\t true label:2 \t result:correct \n",
      "12.) tensor([ 11.5301,   2.8504, -10.4801])   \t predicted label:0\t true label:0 \t result:correct \n",
      "13.) tensor([ 12.6123,   3.1730, -11.5014])   \t predicted label:0\t true label:0 \t result:correct \n",
      "14.) tensor([ 11.6594,   2.9546, -10.6003])   \t predicted label:0\t true label:0 \t result:correct \n",
      "15.) tensor([ 12.2539,   3.0662, -11.1632])   \t predicted label:0\t true label:0 \t result:correct \n",
      "16.) tensor([-2.8531,  9.5883,  3.9502])      \t predicted label:1\t true label:1 \t result:correct \n",
      "17.) tensor([-12.8345,   3.1322,  15.3471])   \t predicted label:2\t true label:2 \t result:correct \n",
      "18.) tensor([0.3871, 9.8778, 0.3246])         \t predicted label:1\t true label:1 \t result:correct \n",
      "19.) tensor([-2.0972,  9.3844,  3.0549])      \t predicted label:1\t true label:1 \t result:correct \n",
      "20.) tensor([-12.7413,   2.8865,  15.2377])   \t predicted label:2\t true label:2 \t result:correct \n",
      "21.) tensor([ 11.0901,   3.0714, -10.0550])   \t predicted label:0\t true label:0 \t result:correct \n",
      "22.) tensor([-6.3775,  6.8391,  7.9654])      \t predicted label:2\t true label:2 \t result:correct \n",
      "23.) tensor([10.8381,  3.5074, -9.8030])      \t predicted label:0\t true label:0 \t result:correct \n",
      "24.) tensor([-12.0274,   3.4492,  14.4198])   \t predicted label:2\t true label:2 \t result:correct \n",
      "25.) tensor([-10.0368,   7.3491,  12.1952])   \t predicted label:2\t true label:2 \t result:correct \n",
      "26.) tensor([-10.7435,   4.3052,  12.9790])   \t predicted label:2\t true label:2 \t result:correct \n",
      "27.) tensor([-11.5495,   4.3333,  13.8681])   \t predicted label:2\t true label:2 \t result:correct \n",
      "28.) tensor([-13.0299,   3.3777,  15.5841])   \t predicted label:2\t true label:2 \t result:correct \n",
      "29.) tensor([10.8508,  3.0849, -9.8269])      \t predicted label:0\t true label:0 \t result:correct \n",
      "30.) tensor([10.9366,  3.2177, -9.9048])      \t predicted label:0\t true label:0 \t result:correct \n",
      "\n",
      "30 flowers are predicted correct out of 30 test flowers.\n"
     ]
    }
   ],
   "source": [
    "num_correct_preds = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_pred = model.forward(data)\n",
    "\n",
    "        # Will tell us what type of flower class our nn thinks it is\n",
    "        print(f'{i+1}.) {str(y_pred):40} \\t predicted label:{y_pred.argmax()}\\t true label:{y_test[i]} \\t result:{'correct' if y_pred.argmax() == y_test[i] else 'wrong'} ')\n",
    "\n",
    "        # Predicted correct or not\n",
    "        if y_pred.argmax().item() == y_test[i]:\n",
    "            num_correct_preds += 1\n",
    "\n",
    "print(f'\\n{num_correct_preds} flowers are predicted correct out of 30 test flowers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f6ed8-98c2-4909-8330-52b840430397",
   "metadata": {},
   "source": [
    "### Create new iris flowers for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80ad03be-d9e8-49cd-a0b3-fa7a7c9e9e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_iris = torch.tensor([4.7, 3.2, 1.3, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39b83761-4a2a-4e44-8614-4d01df5e3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 11.4404,   2.8236, -10.3955])\n",
      "tensor([ 11.4404,   2.8236, -10.3955])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    print(model.forward(new_iris))\n",
    "    print(model(new_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b900a766-245f-4ff4-a9f8-52cdd5510373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.4278,  6.0419,  9.1547])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "newer_iris = torch.tensor([5.9, 3.0, 5.1, 1.8])\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(model(newer_iris))\n",
    "    print(model(newer_iris).argmax().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1635f1b-b535-4164-a6e2-92d19e6b7458",
   "metadata": {},
   "source": [
    "## Save the ANN Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65a98ec7-b56c-4363-87ba-4b8ce5ff8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pytorch_nn_iris_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79edb81a-c76d-42a3-8194-1e1ed645c05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.6032,  0.3151,  0.4249,  1.1511],\n",
       "                      [-0.1096,  0.1009, -0.2434,  0.2936],\n",
       "                      [ 0.5777, -0.6265,  1.0459,  1.0734],\n",
       "                      [ 0.6968,  0.6252, -0.1220, -1.2988],\n",
       "                      [ 0.5829,  0.5930, -0.7273, -1.0887],\n",
       "                      [-0.2304, -0.0586, -0.2031,  0.3317],\n",
       "                      [-0.3947, -0.2305, -0.1412, -0.3006],\n",
       "                      [ 0.6284, -0.2511,  1.1708,  0.4858]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.1330,  0.0832, -1.3409,  1.9024,  1.6684,  0.4040,  0.0547, -0.1934])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.2478, -0.0959,  0.0082,  0.9711,  0.7630, -0.1546,  0.2041,  0.5320],\n",
       "                      [ 0.1795, -0.2155, -0.3500, -0.1366, -0.2712,  0.2901,  0.1018,  0.1464],\n",
       "                      [ 0.2878, -0.0062,  1.0948, -1.3113, -1.0705, -0.2413,  0.1090,  0.3343],\n",
       "                      [ 0.3099, -0.0737,  0.9375, -0.3163, -0.6705, -0.2109,  0.3180,  0.8833],\n",
       "                      [ 0.2224, -0.2918, -0.4779, -0.3924, -0.2961,  0.1432,  0.1266,  0.2159],\n",
       "                      [-0.1826, -0.2410,  0.1876, -0.1429,  0.2146, -0.0839,  0.2022, -0.2747],\n",
       "                      [-0.1784,  0.1078,  0.0747, -0.0901,  0.2107,  0.2403, -0.2564, -0.1888],\n",
       "                      [ 0.3237, -0.1193, -0.1253, -0.3421, -0.2025,  0.0883, -0.0467, -0.2566],\n",
       "                      [ 0.0083, -0.2415, -0.3000, -0.1947, -0.3094, -0.2251,  0.3534,  0.0668]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 7.3529e-01, -3.2975e-01, -1.6700e+00, -2.8776e-01, -5.0088e-02,\n",
       "                      -3.1110e-01, -1.5234e-01, -2.1166e-01,  9.7979e-04])),\n",
       "             ('out.weight',\n",
       "              tensor([[ 0.7381, -0.0231, -0.6743, -1.0034, -0.1434, -0.1141, -0.2631,  0.2795,\n",
       "                       -0.0662],\n",
       "                      [ 0.2201,  0.1039, -1.5991,  0.6709, -0.1439, -0.1278, -0.2767, -0.3314,\n",
       "                        0.0954],\n",
       "                      [-0.6966,  0.1298,  0.9366,  0.9740, -0.2948, -0.0576,  0.0696,  0.1721,\n",
       "                        0.2691]])),\n",
       "             ('out.bias', tensor([ 0.9249, -0.3117, -0.4716]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07dd969-adfd-4e65-a991-4620ccbdb3b0",
   "metadata": {},
   "source": [
    "### Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d3e866e-40a7-4849-912b-45df66ab6125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Model()\n",
    "\n",
    "state_dict = torch.load('pytorch_nn_iris_classifier.pt', weights_only=True)\n",
    "new_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4d4c303-8542-438f-a91c-2f42382d02a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure it has loaded correctly\n",
    "new_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
